{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAXI DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yellow_API_Endpoint = \"https://data.cityofnewyork.us/resource/m6nq-qud6.json\"\n",
    "Green_API_Endpoint = \"https://data.cityofnewyork.us/resource/djnb-wcxt.json\"\n",
    "\n",
    "LIMIT = 1000\n",
    "\n",
    "YELLOW_ROWS = 30000000\n",
    "GREEN_ROWS = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_last_offset(offset_file):\n",
    "    if os.path.exists(offset_file):\n",
    "        with open(offset_file, 'r') as f:\n",
    "            return int(f.read().strip())\n",
    "    return 0  # Default to start from the beginning if no offset file exists\n",
    "\n",
    "def save_last_offset(offset_file, offset):\n",
    "    with open(offset_file, 'w') as f:\n",
    "        f.write(str(offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_csv(df):\n",
    "    # Define the file path\n",
    "    output_path = os.path.join(\"../raw_data\", \"yellow_data.csv\")\n",
    "\n",
    "    # Append to the CSV file, without writing the header if the file already exists\n",
    "    df.to_csv(output_path, mode='a', header=not os.path.exists(output_path), index=False)\n",
    "    print(f\"Appended data to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_taxi_data(api, limit, rows, max_retries=5, retry_delay=10):\n",
    "\n",
    "    folder = \"../raw_data\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    offset_file = os.path.join(folder, \"last_offset.txt\")\n",
    "    offset = load_last_offset(offset_file)\n",
    "\n",
    "    # Progress bar setup\n",
    "    with tqdm(total=rows, desc=\"Fetching Data\", initial=offset, position=0) as pbar:\n",
    "        for i in range(offset, rows, limit):\n",
    "            params = {\n",
    "                \"$limit\": limit,\n",
    "                \"$offset\": i\n",
    "            }\n",
    "\n",
    "            success = False\n",
    "            retries = 0\n",
    "\n",
    "            while not success and retries < max_retries:\n",
    "                try:\n",
    "                    # API request\n",
    "                    response = requests.get(api, params=params, timeout=30)\n",
    "\n",
    "                    if response.status_code == 200:\n",
    "                        data = response.json()\n",
    "\n",
    "                        # Convert to DataFrame\n",
    "                        temp_df = pd.DataFrame(data)\n",
    "\n",
    "                        # Append to CSV file\n",
    "                        append_to_csv(temp_df)\n",
    "\n",
    "                        # Update progress bar and offset\n",
    "                        pbar.update(len(data))\n",
    "                        save_last_offset(offset_file, i + len(data))  # Save offset after successful fetch\n",
    "                        success = True\n",
    "\n",
    "                    else:\n",
    "                        print(f\"Error: Status Code {response.status_code}. Retrying...\")\n",
    "                        retries += 1\n",
    "                        time.sleep(retry_delay)\n",
    "\n",
    "                except requests.exceptions.ConnectionError as e:\n",
    "                    print(f\"Connection error: {e}. Retrying ({retries + 1}/{max_retries})...\")\n",
    "                    retries += 1\n",
    "                    time.sleep(retry_delay)\n",
    "\n",
    "                except requests.exceptions.Timeout as e:\n",
    "                    print(f\"Timeout error: {e}. Retrying ({retries + 1}/{max_retries})...\")\n",
    "                    retries += 1\n",
    "                    time.sleep(retry_delay)\n",
    "\n",
    "            if not success:\n",
    "                print(f\"Failed to fetch data after {max_retries} retries. Offset: {i}\")\n",
    "                break\n",
    "\n",
    "    print(\"Data fetching complete!\")\n",
    "\n",
    "def fetch_simple(api, limit, rows, output_file):\n",
    "    folder = \"../raw_data\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Initialize progress bar\n",
    "    with tqdm(total=rows, desc=\"Fetching Data\") as pbar:\n",
    "        for i in range(0, rows, limit):\n",
    "            params = {\n",
    "                \"$limit\": limit,\n",
    "                \"$offset\": i\n",
    "            }\n",
    "\n",
    "            # API request\n",
    "            response = requests.get(api, params=params, timeout=30)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                temp_df = pd.DataFrame(data)\n",
    "\n",
    "                # Append to CSV file\n",
    "                if not os.path.exists(output_file):\n",
    "                    temp_df.to_csv(output_file, index=False)  # Write header if file doesn't exist\n",
    "                else:\n",
    "                    temp_df.to_csv(output_file, mode='a', index=False, header=False)  # Append data without header\n",
    "\n",
    "                # Update progress bar\n",
    "                pbar.update(len(data))\n",
    "            else:\n",
    "                print(f\"Error: Status Code {response.status_code}. Skipping offset {i}...\")\n",
    "\n",
    "    print(\"Data fetching complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Data: 100%|██████████| 1000000/1000000 [31:49<00:00, 523.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetching complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fetch_taxi_data(Yellow_API_Endpoint, LIMIT, YELLOW_ROWS)\n",
    "fetch_simple(Green_API_Endpoint, LIMIT, GREEN_ROWS, \"green_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
